{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Barbara\\anaconda3\\envs\\nlp_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from typing import List, Union\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                ids: List[str], \n",
    "                speakers: List[str], \n",
    "                sexes: List[str], \n",
    "                texts: List[str], \n",
    "                texts_en: List[str], \n",
    "                labels: List[bool],\n",
    "                device: torch.device = torch.device('cpu'),\n",
    "                model_name: str = 'distilbert/distilbert-base-uncased-finetuned-sst-2-english',\n",
    "                max_length: int = 512\n",
    "        ):\n",
    "        assert len(ids) == len(speakers) == len(sexes) == len(texts) == len(texts_en) == len(labels)\n",
    "        self.ids = []\n",
    "        self.speakers = []\n",
    "        self.sexes = []\n",
    "        self.texts = []\n",
    "        self.texts_en = []\n",
    "        self.embeddings = []\n",
    "        self.attention_masks = []\n",
    "        self.labels = []\n",
    "        self.device = device\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        \n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "        for i in range(len(ids)):\n",
    "            inputs = self.tokenizer(texts[i], add_special_tokens=True, return_tensors='pt', padding='max_length',max_length=max_length)\n",
    "            if inputs['input_ids'].shape[1] <= max_length:\n",
    "                inputs = self.tokenizer(texts_en[i], add_special_tokens=True, return_tensors='pt', padding='max_length',max_length=max_length)\n",
    "                self.ids.append(ids[i])\n",
    "                self.speakers.append(speakers[i])\n",
    "                self.sexes.append(sexes[i])\n",
    "                self.texts.append(texts[i])\n",
    "                self.texts_en.append(texts_en[i])\n",
    "                self.embeddings.append(inputs['input_ids'][0])\n",
    "                self.attention_masks.append(inputs['attention_mask'])\n",
    "                self.labels.append(torch.tensor((labels[i]), dtype=torch.long))\n",
    "                \n",
    "        print(f'Loaded {len(self.ids)}/{len(ids)} samples.')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.ids[index], self.speakers[index], self.sexes[index], self.texts[index], \\\n",
    "                self.texts_en[index], self.embeddings[index][:512].to(self.device), self.attention_masks[index][0][:512].to(self.device), self.labels[index]\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def set_device(self, device: torch.device):\n",
    "        '''\n",
    "        Sets the device to the given device.\n",
    "        '''\n",
    "        self.device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Barbara\\AppData\\Local\\Temp\\ipykernel_6744\\968643015.py:46: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  self.labels.append(torch.tensor((labels[i]), dtype=torch.long))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 538/3438 samples.\n",
      "Processed orientation-at-train.tsv, created train, val, and test datasets of size 431, 54, and 53 respectively.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Barbara\\AppData\\Local\\Temp\\ipykernel_6744\\968643015.py:46: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  self.labels.append(torch.tensor((labels[i]), dtype=torch.long))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 398/1249 samples.\n",
      "Processed orientation-ba-train.tsv, created train, val, and test datasets of size 319, 40, and 39 respectively.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Barbara\\AppData\\Local\\Temp\\ipykernel_6744\\968643015.py:46: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  self.labels.append(torch.tensor((labels[i]), dtype=torch.long))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 759/2220 samples.\n",
      "Processed orientation-be-train.tsv, created train, val, and test datasets of size 608, 76, and 75 respectively.\n",
      "Loaded 0/3907 samples.\n",
      "Processed orientation-bg-train.tsv, created train, val, and test datasets of size 0, 0, and 0 respectively.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Barbara\\anaconda3\\envs\\nlp_env\\lib\\site-packages\\torch\\utils\\data\\dataset.py:473: UserWarning: Length of split at index 0 is 0. This might result in an empty dataset.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Barbara\\anaconda3\\envs\\nlp_env\\lib\\site-packages\\torch\\utils\\data\\dataset.py:473: UserWarning: Length of split at index 1 is 0. This might result in an empty dataset.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Barbara\\anaconda3\\envs\\nlp_env\\lib\\site-packages\\torch\\utils\\data\\dataset.py:473: UserWarning: Length of split at index 2 is 0. This might result in an empty dataset.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Barbara\\AppData\\Local\\Temp\\ipykernel_6744\\968643015.py:46: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  self.labels.append(torch.tensor((labels[i]), dtype=torch.long))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 961/4136 samples.\n",
      "Processed orientation-cz-train.tsv, created train, val, and test datasets of size 769, 96, and 96 respectively.\n",
      "Loaded 840/3069 samples.\n",
      "Processed orientation-dk-train.tsv, created train, val, and test datasets of size 672, 84, and 84 respectively.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Barbara\\AppData\\Local\\Temp\\ipykernel_6744\\968643015.py:46: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  self.labels.append(torch.tensor((labels[i]), dtype=torch.long))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1514/2580 samples.\n",
      "Processed orientation-ee-train.tsv, created train, val, and test datasets of size 1212, 151, and 151 respectively.\n",
      "Loaded 98/2077 samples.\n",
      "Processed orientation-es-ct-train.tsv, created train, val, and test datasets of size 79, 10, and 9 respectively.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Barbara\\AppData\\Local\\Temp\\ipykernel_6744\\968643015.py:46: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  self.labels.append(torch.tensor((labels[i]), dtype=torch.long))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 17/850 samples.\n",
      "Processed orientation-es-ga-train.tsv, created train, val, and test datasets of size 14, 2, and 1 respectively.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Barbara\\AppData\\Local\\Temp\\ipykernel_6744\\968643015.py:46: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  self.labels.append(torch.tensor((labels[i]), dtype=torch.long))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 120/4767 samples.\n",
      "Processed orientation-es-train.tsv, created train, val, and test datasets of size 96, 12, and 12 respectively.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Barbara\\AppData\\Local\\Temp\\ipykernel_6744\\968643015.py:46: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  self.labels.append(torch.tensor((labels[i]), dtype=torch.long))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 320/740 samples.\n",
      "Processed orientation-fi-train.tsv, created train, val, and test datasets of size 256, 32, and 32 respectively.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Barbara\\AppData\\Local\\Temp\\ipykernel_6744\\968643015.py:46: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  self.labels.append(torch.tensor((labels[i]), dtype=torch.long))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1561/2293 samples.\n",
      "Processed orientation-fr-train.tsv, created train, val, and test datasets of size 1249, 156, and 156 respectively.\n",
      "Loaded 15196/24239 samples.\n",
      "Processed orientation-gb-train.tsv, created train, val, and test datasets of size 12157, 1520, and 1519 respectively.\n",
      "Loaded 0/5639 samples.\n",
      "Processed orientation-gr-train.tsv, created train, val, and test datasets of size 0, 0, and 0 respectively.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Barbara\\anaconda3\\envs\\nlp_env\\lib\\site-packages\\torch\\utils\\data\\dataset.py:473: UserWarning: Length of split at index 0 is 0. This might result in an empty dataset.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Barbara\\anaconda3\\envs\\nlp_env\\lib\\site-packages\\torch\\utils\\data\\dataset.py:473: UserWarning: Length of split at index 1 is 0. This might result in an empty dataset.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Barbara\\anaconda3\\envs\\nlp_env\\lib\\site-packages\\torch\\utils\\data\\dataset.py:473: UserWarning: Length of split at index 2 is 0. This might result in an empty dataset.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Barbara\\AppData\\Local\\Temp\\ipykernel_6744\\968643015.py:46: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  self.labels.append(torch.tensor((labels[i]), dtype=torch.long))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2238/6507 samples.\n",
      "Processed orientation-hr-train.tsv, created train, val, and test datasets of size 1791, 224, and 223 respectively.\n",
      "Loaded 94/2935 samples.\n",
      "Processed orientation-hu-train.tsv, created train, val, and test datasets of size 76, 9, and 9 respectively.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Barbara\\AppData\\Local\\Temp\\ipykernel_6744\\968643015.py:46: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  self.labels.append(torch.tensor((labels[i]), dtype=torch.long))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 113/533 samples.\n",
      "Processed orientation-is-train.tsv, created train, val, and test datasets of size 91, 11, and 11 respectively.\n",
      "Loaded 656/3367 samples.\n",
      "Processed orientation-it-train.tsv, created train, val, and test datasets of size 525, 66, and 65 respectively.\n",
      "Loaded 185/798 samples.\n",
      "Processed orientation-lv-train.tsv, created train, val, and test datasets of size 149, 18, and 18 respectively.\n",
      "Loaded 2319/5657 samples.\n",
      "Processed orientation-nl-train.tsv, created train, val, and test datasets of size 1856, 232, and 231 respectively.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Barbara\\AppData\\Local\\Temp\\ipykernel_6744\\968643015.py:46: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  self.labels.append(torch.tensor((labels[i]), dtype=torch.long))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2507/10861 samples.\n",
      "Processed orientation-no-train.tsv, created train, val, and test datasets of size 2006, 251, and 250 respectively.\n",
      "Loaded 1502/5489 samples.\n",
      "Processed orientation-pl-train.tsv, created train, val, and test datasets of size 1202, 150, and 150 respectively.\n",
      "Loaded 641/3464 samples.\n",
      "Processed orientation-pt-train.tsv, created train, val, and test datasets of size 513, 64, and 64 respectively.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Barbara\\AppData\\Local\\Temp\\ipykernel_6744\\968643015.py:46: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  self.labels.append(torch.tensor((labels[i]), dtype=torch.long))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1173/9789 samples.\n",
      "Processed orientation-rs-train.tsv, created train, val, and test datasets of size 939, 117, and 117 respectively.\n",
      "Loaded 1215/8425 samples.\n",
      "Processed orientation-se-train.tsv, created train, val, and test datasets of size 973, 121, and 121 respectively.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Barbara\\AppData\\Local\\Temp\\ipykernel_6744\\968643015.py:46: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  self.labels.append(torch.tensor((labels[i]), dtype=torch.long))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 365/2518 samples.\n",
      "Processed orientation-si-train.tsv, created train, val, and test datasets of size 293, 36, and 36 respectively.\n",
      "Loaded 5085/16138 samples.\n",
      "Processed orientation-tr-train.tsv, created train, val, and test datasets of size 4069, 508, and 508 respectively.\n",
      "Loaded 0/2545 samples.\n",
      "Processed orientation-ua-train.tsv, created train, val, and test datasets of size 0, 0, and 0 respectively.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Barbara\\anaconda3\\envs\\nlp_env\\lib\\site-packages\\torch\\utils\\data\\dataset.py:473: UserWarning: Length of split at index 0 is 0. This might result in an empty dataset.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Barbara\\anaconda3\\envs\\nlp_env\\lib\\site-packages\\torch\\utils\\data\\dataset.py:473: UserWarning: Length of split at index 1 is 0. This might result in an empty dataset.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Barbara\\anaconda3\\envs\\nlp_env\\lib\\site-packages\\torch\\utils\\data\\dataset.py:473: UserWarning: Length of split at index 2 is 0. This might result in an empty dataset.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed all files, created train, val, and test datasets of size 32345, 4040, and 4030 respectively.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from dataset import MyDataset\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "from typing import List\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "english_speaking_countries = ['gb']\n",
    "\n",
    "DATA_DIR = \"data/orientation\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_NAME = \"roberta-base\"\n",
    "OUTPUT_DIR = \"data/torch/orientation\"\n",
    "\n",
    "def load_data(file_path: str):\n",
    "    '''\n",
    "    Loads specified dataset and returns lists of columns\n",
    "    '''\n",
    "    country_code = file_path.split('-')[1]  # Extract country code from filename\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, delimiter='\\t', quoting=3, on_bad_lines='skip')\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    if country_code in english_speaking_countries:\n",
    "        df['text_combined'] = df['text']\n",
    "    else:\n",
    "        df['text_combined'] = df['text_en']\n",
    "    # Drop rows where 'text_combined' is NaN or empty\n",
    "    df = df.dropna(subset=['text_combined'])\n",
    "    df = df[df['text_combined'] != '']\n",
    "    df['file_path'] = file_path  # Add file path information\n",
    "    return list(df['id']), list(df['speaker']), list(df['sex']), list(df['text']), list(df['text_combined']), list(df['label'])\n",
    "\n",
    "def train_val_test_split_country(data: MyDataset, val_size:float = 0.1, test_size:float = 0.1, random_state:int = 42):\n",
    "    train_size = 1 - test_size - val_size\n",
    "    train_data, val_data, test_data = random_split(data, [train_size, val_size, test_size], \\\n",
    "                                                   generator=torch.Generator().manual_seed(random_state))\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = [], [], []\n",
    "for filename in os.listdir(DATA_DIR):\n",
    "    if filename.endswith(\".tsv\"):\n",
    "        file_path = os.path.join(DATA_DIR, filename)\n",
    "        ids, speakers, sexes, texts, texts_en, labels = load_data(file_path)\n",
    "        df = MyDataset(\n",
    "            ids=ids,\n",
    "            speakers=speakers,\n",
    "            sexes=sexes,\n",
    "            texts=texts,\n",
    "            texts_en=texts_en,\n",
    "            labels=labels,\n",
    "            device=DEVICE,\n",
    "            model_name=MODEL_NAME\n",
    "        )\n",
    "        train_df, val_df, test_df = train_val_test_split_country(df)\n",
    "        train_dataset.append(train_df)\n",
    "        val_dataset.append(val_df)\n",
    "        test_dataset.append(test_df)\n",
    "        torch.save(train_df, os.path.join(OUTPUT_DIR, f\"train_dataset_{filename.replace('-train.tsv', '.pt')}\"))\n",
    "        torch.save(val_df, os.path.join(OUTPUT_DIR, f\"val_dataset_{filename.replace('-train.tsv', '.pt')}\"))\n",
    "        torch.save(test_df, os.path.join(OUTPUT_DIR, f\"test_dataset_{filename.replace('-train.tsv', '.pt')}\"))\n",
    "        breakpoint()\n",
    "        print(f\"Processed {filename}, created train, val, and test datasets of size {len(train_df)}, {len(val_df)}, and {len(test_df)} respectively.\")\n",
    "\n",
    "train_dataset = torch.utils.data.ConcatDataset(train_dataset)\n",
    "val_dataset = torch.utils.data.ConcatDataset(val_dataset)\n",
    "test_dataset = torch.utils.data.ConcatDataset(test_dataset)\n",
    "\n",
    "torch.save(train_dataset, os.path.join(OUTPUT_DIR, \"train_dataset_all.pt\"))\n",
    "torch.save(val_dataset, os.path.join(OUTPUT_DIR, \"val_dataset_all.pt\"))\n",
    "torch.save(test_dataset, os.path.join(OUTPUT_DIR, \"test_dataset_all.pt\"))\n",
    "\n",
    "print(f\"Processed all files, created train, val, and test datasets of size {len(train_dataset)}, {len(val_dataset)}, and {len(test_dataset)} respectively.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_env)",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
