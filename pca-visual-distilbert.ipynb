{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10558461,"sourceType":"datasetVersion","datasetId":6532163},{"sourceId":62488,"sourceType":"modelInstanceVersion","modelInstanceId":52188,"modelId":71587},{"sourceId":239050,"sourceType":"modelInstanceVersion","modelInstanceId":204153,"modelId":225888}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from torch.utils.data import Dataset\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nfrom typing import List, Union\nfrom transformers import AutoTokenizer, AutoModel\n\nclass MyDataset(Dataset):\n    def __init__(self, \n                ids: List[str], \n                speakers: List[str], \n                sexes: List[str], \n                texts: List[str], \n                texts_en: List[str], \n                labels: List[bool],\n                device: torch.device = torch.device('cpu'),\n                model_name: str = 'distilbert/distilbert-base-uncased-finetuned-sst-2-english',\n                max_length: int = 512\n        ):\n        assert len(ids) == len(speakers) == len(sexes) == len(texts) == len(texts_en) == len(labels)\n        self.ids = []\n        self.speakers = []\n        self.sexes = []\n        self.texts = []\n        self.texts_en = []\n        self.embeddings = []\n        self.attention_masks = []\n        self.labels = []\n        self.device = device\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n        \n        if self.tokenizer.pad_token is None:\n            self.tokenizer.pad_token = self.tokenizer.eos_token\n\n        for i in range(len(ids)):\n            text = texts[i]\n            inputs = self.tokenizer(text, add_special_tokens=True, return_tensors='pt', padding='max_length',max_length=max_length)\n            if inputs['input_ids'].shape[1] <= max_length:\n                self.ids.append(ids[i])\n                self.speakers.append(speakers[i])\n                self.sexes.append(sexes[i])\n                self.texts.append(texts[i])\n                self.texts_en.append(texts_en[i])\n                self.embeddings.append(inputs['input_ids'][0])\n                self.attention_masks.append(inputs['attention_mask'])\n                self.labels.append(torch.tensor((labels[i]), dtype=torch.long))\n                \n        print(f'Loaded {len(self.ids)}/{len(ids)} samples.')\n\n    def __getitem__(self, index):\n        return self.ids[index], self.speakers[index], self.sexes[index], self.texts[index], \\\n                self.texts_en[index], self.embeddings[index].to(self.device), self.attention_masks[index][0].to(self.device), self.labels[index]\n            \n    def __len__(self):\n        return len(self.ids)\n\n    def set_device(self, device: torch.device):\n        '''\n        Sets the device to the given device.\n        '''\n        self.device = device","metadata":{"execution":{"iopub.status.busy":"2025-01-28T10:07:20.788273Z","iopub.execute_input":"2025-01-28T10:07:20.788551Z","iopub.status.idle":"2025-01-28T10:07:30.680898Z","shell.execute_reply.started":"2025-01-28T10:07:20.788528Z","shell.execute_reply":"2025-01-28T10:07:30.680240Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nfrom typing import List, Union\nfrom transformers import AutoTokenizer, AutoModel, PreTrainedModel\nfrom transformers import DistilBertTokenizer, DistilBertForSequenceClassification, BertForSequenceClassification\nimport pandas as pd\n\nfrom transformers import DataCollatorWithPadding\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\ndef evaluate(dataset: Dataset, model: PreTrainedModel, device: torch.device = torch.device('cpu'), batch_size = 1):\n    '''\n    Evaluates the model on the given dataset.\n    \n    Parameters:\n        dataset: Dataset\n            The dataset to evaluate on.\n        model: PreTrainedModel\n            The model to evaluate.\n        device: torch.device\n            The device to use.\n        plot: bool\n    '''\n    model.to(device)\n    model.eval()\n\n    #tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased\")\n    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n    #data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n    #loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=data_collator)\n    correct_labels = []\n    model_predictions = []\n    with torch.no_grad():\n        for batch in loader:\n            id_, speaker, sex, text, text_en, embedding, attention_mask, label = batch\n            embedding = embedding.to(device)\n            attention_mask = attention_mask.to(device).squeeze(1)\n            label = label.to(device)\n            model_output = model(input_ids=embedding, labels=label, attention_mask=attention_mask)\n            logits = model_output.logits\n            predictions = torch.argmax(logits, dim=1)\n            correct_labels.extend(label.cpu().numpy())\n            model_predictions.extend(predictions.cpu().numpy())\n\n    accuracy = accuracy_score(correct_labels, model_predictions)\n    cls_dict = classification_report(correct_labels, model_predictions, zero_division = 0.0, output_dict=True)\n    print(classification_report(correct_labels, model_predictions, zero_division = 0.0))\n    print(f'Accuracy: {accuracy}')\n    print(f'Confusion matrix:\\n{confusion_matrix(correct_labels, model_predictions)}')\n    return cls_dict","metadata":{"execution":{"iopub.status.busy":"2025-01-28T10:07:34.206032Z","iopub.execute_input":"2025-01-28T10:07:34.206494Z","iopub.status.idle":"2025-01-28T10:07:46.951987Z","shell.execute_reply.started":"2025-01-28T10:07:34.206467Z","shell.execute_reply":"2025-01-28T10:07:46.951265Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import types\n\ndataset_valid = torch.load('/kaggle/input/orientation-dataset/val_dataset_all.pt')\ndataset_train = torch.load('/kaggle/input/orientation-dataset/train_dataset_all.pt')\ndataset_test = torch.load('/kaggle/input/orientation-dataset/test_dataset_all.pt')","metadata":{"execution":{"iopub.status.busy":"2025-01-28T10:07:54.029427Z","iopub.execute_input":"2025-01-28T10:07:54.029998Z","iopub.status.idle":"2025-01-28T10:08:22.210768Z","shell.execute_reply.started":"2025-01-28T10:07:54.029969Z","shell.execute_reply":"2025-01-28T10:08:22.210112Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"left_v = 0\nright_v = 0\nfor example in dataset_valid:\n    if example[-1] == 0:\n        left_v += 1\n    else:\n        right_v += 1\n\nprint(f'Validation set: {left_v} left, {right_v} right')","metadata":{"execution":{"iopub.status.busy":"2025-01-28T10:08:25.358519Z","iopub.execute_input":"2025-01-28T10:08:25.358810Z","iopub.status.idle":"2025-01-28T10:08:25.413418Z","shell.execute_reply.started":"2025-01-28T10:08:25.358787Z","shell.execute_reply":"2025-01-28T10:08:25.412731Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"left_t = 0\nright_t = 0\nfor example in dataset_train:\n    if example[-1] == 0:\n        left_t += 1\n    else:\n        right_t += 1\n    \nprint(f'Training set: {left_t} left, {right_t} right')","metadata":{"execution":{"iopub.status.busy":"2025-01-28T10:08:27.789053Z","iopub.execute_input":"2025-01-28T10:08:27.789342Z","iopub.status.idle":"2025-01-28T10:08:28.149872Z","shell.execute_reply.started":"2025-01-28T10:08:27.789321Z","shell.execute_reply":"2025-01-28T10:08:28.149125Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"left_tt = 0\nright_tt = 0\nfor example in dataset_test:\n    if example[-1] == 0:\n        left_tt += 1\n    else:\n        right_tt += 1\n\nprint(f'Test set: {left_tt} left, {right_tt} right')","metadata":{"execution":{"iopub.status.busy":"2025-01-28T10:08:30.484589Z","iopub.execute_input":"2025-01-28T10:08:30.484875Z","iopub.status.idle":"2025-01-28T10:08:30.539729Z","shell.execute_reply.started":"2025-01-28T10:08:30.484851Z","shell.execute_reply":"2025-01-28T10:08:30.539102Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"left_total = left_v+left_t+left_tt\nright_total = right_v+right_t+right_tt","metadata":{"execution":{"iopub.status.busy":"2025-01-28T10:08:34.606405Z","iopub.execute_input":"2025-01-28T10:08:34.606690Z","iopub.status.idle":"2025-01-28T10:08:34.610401Z","shell.execute_reply.started":"2025-01-28T10:08:34.606669Z","shell.execute_reply":"2025-01-28T10:08:34.609435Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f'Left: {left_total}, Right: {right_total}')","metadata":{"execution":{"iopub.status.busy":"2025-01-28T10:08:36.478310Z","iopub.execute_input":"2025-01-28T10:08:36.478598Z","iopub.status.idle":"2025-01-28T10:08:36.483277Z","shell.execute_reply.started":"2025-01-28T10:08:36.478575Z","shell.execute_reply":"2025-01-28T10:08:36.482362Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f'Left: {left_total/(left_total+right_total)*100:.2f}%, Right: {right_total/(left_total+right_total)*100:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2025-01-28T10:08:39.144213Z","iopub.execute_input":"2025-01-28T10:08:39.144544Z","iopub.status.idle":"2025-01-28T10:08:39.148944Z","shell.execute_reply.started":"2025-01-28T10:08:39.144515Z","shell.execute_reply":"2025-01-28T10:08:39.148078Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nDATASET_DIR = '/kaggle/input/orientation-dataset'\nc_dict = {'train': {}, 'val': {}, 'test': {}}\nfor filename in os.listdir(DATASET_DIR):\n    if filename.endswith(\".pt\"):\n        file_path = os.path.join(DATASET_DIR, filename)\n        dataset = torch.load(file_path)\n        if 'train' in filename:\n            c_dict['train'][filename] = dataset\n\n        elif 'val' in filename:\n            c_dict['val'][filename] = dataset\n\n        elif 'test' in filename:\n            c_dict['test'][filename] = dataset","metadata":{"execution":{"iopub.status.busy":"2025-01-28T10:08:41.890386Z","iopub.execute_input":"2025-01-28T10:08:41.890670Z","iopub.status.idle":"2025-01-28T10:09:29.618143Z","shell.execute_reply.started":"2025-01-28T10:08:41.890648Z","shell.execute_reply":"2025-01-28T10:09:29.617238Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for key in c_dict:\n    print(key)\n    for filename in c_dict[key]:\n        print(f'    {filename}: {len(c_dict[key][filename])}')","metadata":{"execution":{"iopub.status.busy":"2025-01-28T10:09:38.552035Z","iopub.execute_input":"2025-01-28T10:09:38.552367Z","iopub.status.idle":"2025-01-28T10:09:38.569892Z","shell.execute_reply.started":"2025-01-28T10:09:38.552341Z","shell.execute_reply":"2025-01-28T10:09:38.568998Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoModel\nmodel = torch.load('/kaggle/input/distilbert/pytorch/default/1/distilbert_cased_en_novi.pt', map_location=torch.device('cuda:0'))","metadata":{"execution":{"iopub.status.busy":"2025-01-28T10:09:44.338132Z","iopub.execute_input":"2025-01-28T10:09:44.338449Z","iopub.status.idle":"2025-01-28T10:09:47.010880Z","shell.execute_reply.started":"2025-01-28T10:09:44.338421Z","shell.execute_reply":"2025-01-28T10:09:47.010010Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2025-01-28T10:09:49.211206Z","iopub.execute_input":"2025-01-28T10:09:49.211493Z","iopub.status.idle":"2025-01-28T10:09:49.217740Z","shell.execute_reply.started":"2025-01-28T10:09:49.211470Z","shell.execute_reply":"2025-01-28T10:09:49.217080Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nfrom typing import List, Union\nfrom transformers import AutoTokenizer, AutoModel, PreTrainedModel\nfrom transformers import DistilBertTokenizer, DistilBertForSequenceClassification, BertForSequenceClassification\nimport pandas as pd\n\nfrom transformers import DataCollatorWithPadding\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\ndef evaluate(dataset: Dataset, model: PreTrainedModel, device: torch.device = torch.device('cpu'), batch_size=1):\n    \"\"\"\n    Evaluates the model on the given dataset, ignoring sequences longer than 512 tokens.\n\n    Parameters:\n        dataset: Dataset\n            The dataset to evaluate on.\n        model: PreTrainedModel\n            The model to evaluate.\n        device: torch.device\n            The device to use.\n        batch_size: int\n            The batch size for evaluation.\n    \"\"\"\n    model.to(device)\n    model.eval()\n\n    def filter_and_collate(batch):\n        \"\"\"\n        Custom collate function that filters out inputs longer than 512 tokens.\n        \"\"\"\n        filtered_batch = []\n        for item in batch:\n            embedding = item[5]  # Assuming 'embedding' or 'input_ids' is at index 5\n            if len(embedding) <= 512:\n                filtered_batch.append(item)\n\n        if len(filtered_batch) == 0:\n            return None  # Return None if no valid examples remain in the batch\n\n        # Convert filtered items to tensors\n        ids = [item[0] for item in filtered_batch]\n        speakers = [item[1] for item in filtered_batch]\n        sexes = [item[2] for item in filtered_batch]\n        texts = [item[3] for item in filtered_batch]\n        texts_en = [item[4] for item in filtered_batch]\n        embeddings = torch.stack([torch.tensor(item[5]) for item in filtered_batch])\n        attention_masks = torch.stack([torch.tensor(item[6]) for item in filtered_batch])\n        labels = torch.tensor([item[7] for item in filtered_batch])\n\n        return {\n            'ids': ids,\n            'speakers': speakers,\n            'sexes': sexes,\n            'texts': texts,\n            'texts_en': texts_en,\n            'input_ids': embeddings,\n            'attention_mask': attention_masks,\n            'labels': labels,\n        }\n\n    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=filter_and_collate)\n\n    correct_labels = []\n    model_predictions = []\n\n    with torch.no_grad():\n        for batch in loader:\n            if batch is None:\n                continue  # Skip empty batches\n\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n\n            model_output = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n            logits = model_output.logits\n            predictions = torch.argmax(logits, dim=1)\n\n            correct_labels.extend(labels.cpu().numpy())\n            model_predictions.extend(predictions.cpu().numpy())\n\n    # Calculate metrics\n    accuracy = accuracy_score(correct_labels, model_predictions)\n    cls_dict = classification_report(correct_labels, model_predictions, zero_division=0.0, output_dict=True)\n    print(classification_report(correct_labels, model_predictions, zero_division=0.0))\n    print(f'Accuracy: {accuracy}')\n    print(f'Confusion matrix:\\n{confusion_matrix(correct_labels, model_predictions)}')\n\n    return cls_dict\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T10:12:23.071830Z","iopub.execute_input":"2025-01-28T10:12:23.072268Z","iopub.status.idle":"2025-01-28T10:12:23.084323Z","shell.execute_reply.started":"2025-01-28T10:12:23.072236Z","shell.execute_reply":"2025-01-28T10:12:23.083401Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nperformance = {}\nfor filename in c_dict['test']:\n    dataset_ = c_dict['test'][filename]\n    print(f'{filename}: {len(dataset_)} examples')\n    report = evaluate(dataset_, model, device=device,batch_size=16)\n    performance[filename] = report['weighted avg']['f1-score']","metadata":{"execution":{"iopub.status.busy":"2025-01-28T10:12:33.482404Z","iopub.execute_input":"2025-01-28T10:12:33.482690Z","iopub.status.idle":"2025-01-28T10:13:32.892906Z","shell.execute_reply.started":"2025-01-28T10:12:33.482668Z","shell.execute_reply":"2025-01-28T10:13:32.892034Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\nimport numpy as np\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\n# Ensure inline plotting for Jupyter notebooks\n%matplotlib inline\n\ndef filter_and_collate(batch):\n    \"\"\"\n    Custom collate function that filters out inputs longer than 512 tokens.\n    \"\"\"\n    filtered_batch = []\n    for item in batch:\n        embedding = item[5]  # Assuming 'embedding' or 'input_ids' is at index 5\n    if len(embedding) <= 512:\n        filtered_batch.append(item)\n\n    if len(filtered_batch) == 0:\n        return None  # Return None if no valid examples remain in the batch\n\n    # Convert filtered items to tensors\n    ids = [item[0] for item in filtered_batch]\n    speakers = [item[1] for item in filtered_batch]\n    sexes = [item[2] for item in filtered_batch]\n    texts = [item[3] for item in filtered_batch]\n    texts_en = [item[4] for item in filtered_batch]\n    embeddings = torch.stack([torch.tensor(item[5]) for item in filtered_batch])\n    attention_masks = torch.stack([torch.tensor(item[6]) for item in filtered_batch])\n    labels = torch.tensor([item[7] for item in filtered_batch])\n\n    return {\n        'ids': ids,\n        'speakers': speakers,\n        'sexes': sexes,\n        'texts': texts,\n        'texts_en': texts_en,\n        'input_ids': embeddings,\n        'attention_mask': attention_masks,\n        'labels': labels,\n    }\n\n# Extract country code from file path\ndef extract_country_code(file_path):\n    if 'all' in file_path:\n        return 'all_combined'\n    if 'train' in file_path:\n        match = re.search(r'orientation-([a-z]{2}(?:-[a-z]{2})?).pt', file_path)\n        if match:\n            return match.group(1)\n    \n    if 'val' in file_path:\n        match = re.search(r'val_dataset_orientation-([a-z]{2}(?:-[a-z]{2})?).pt', file_path)\n        if match:\n            return match.group(1)\n        \n    if 'test' in file_path:\n        match = re.search(r'orientation-([a-z]{2}(?:-[a-z]{2})?).pt', file_path)\n        if match:\n            return match.group(1)\n        \n    print(f\"No match found for: {file_path}\")\n    return None\n\ndef get_bert_representations(model, dataset_name, dataset, batch_size=1):\n    representations = []\n    labels = []\n    countries = []\n    sexes = []\n    logits = []\n    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=filter_and_collate)\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    for ind, batch in enumerate(dataloader):\n        if batch is None:\n            continue\n        \n        #id_, speaker, sex, text, text_en, embedding, attention_mask, label = batch\n        embedding = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        label = batch['labels']\n        sex = batch['sexes']\n        # Get the last hidden state\n        outputs = model(input_ids=embedding, attention_mask=attention_mask, output_hidden_states=True)\n        hidden_states = outputs.hidden_states\n        cls_representation = hidden_states[-1][:,0,:]\n        logits_ = outputs.logits\n        representations.extend(cls_representation.detach().cpu().numpy())\n        labels.extend(label.detach().cpu().numpy())\n        countries.extend([extract_country_code(dataset_name) for _ in range(len(label))])\n        sexes.extend(sex)\n        logits.extend(logits_.detach().cpu().numpy())\n            \n    sexes = list(map(lambda x: 0 if x == 'F' else 1, sexes))\n    return np.array(representations), np.array(labels), np.array(countries), np.array(sexes), np.array(logits)\n\ndef extract_representations(dataset_dict):\n    representations = np.array([])\n    labels = np.array([])\n    countries = np.array([])\n    sexes = np.array([])\n    logits = np.array([])\n    for file_path, dataset in dataset_dict.items():\n        reps_, labels_, countries_, sexes_, logits_ = get_bert_representations(model, file_path, dataset, 16)\n        print(reps_)\n        print(\"shape: \", reps_.shape)\n        representations = np.concatenate([representations, reps_]) if representations.size else reps_\n        labels = np.concatenate([labels, labels_]) if labels.size else labels_\n        countries = np.concatenate([countries, countries_]) if countries.size else countries_\n        sexes = np.concatenate([sexes, sexes_]) if sexes.size else sexes_\n        logits = np.concatenate([logits, logits_]) if logits.size else logits_\n        print(f\"Processed {file_path}\")\n        \n    return representations, labels, countries, sexes, logits\n\ndef calculate_mean_by_country(countries, labels, representations, threshold=1.0):\n    mean_representations = {}\n    for country in np.unique(countries):\n        if representations[(countries == country)].shape[0] < threshold:\n            print(country)\n            continue\n        for label in np.unique(labels):\n            reps = representations[(countries == country) & (labels == label)]\n            mean_representations[(country, label)] = np.mean(reps, axis=0)\n    \n    return mean_representations\n\ndef calculate_mean_by_country_sex(countries, labels, representations, sexes, threshold=1.0):\n    mean_representations = {}\n    for country in np.unique(countries):\n        if representations[(countries == country)].shape[0] < threshold:\n            continue\n        for sex in np.unique(sexes):\n            for label in np.unique(labels):\n                reps = representations[(countries == country) & (sexes == sex) & (labels == label)]\n                if reps.size:\n                    mean_representations[(country, sex, label)] = np.mean(reps, axis=0)\n                else:\n                    mean_representations[(country, sex, label)] = np.zeros([768])\n                \n    return mean_representations\n\ndef perform_PCA(vectors):\n    pca = PCA(n_components=2)\n    pca_result = pca.fit_transform(vectors)\n    return pca_result \n    \ndef plot_country(pca_result, countries_labels):\n    plt.figure(figsize=(25, 14))\n\n    for i, ((country, label), pca_coord) in enumerate(zip(countries_labels, pca_result)):\n        color = 'red' if label == 0 else 'blue'\n        plt.scatter(pca_coord[0], pca_coord[1], color=color)\n\n    # Connect the points with lines and add country codes\n    for country in np.unique([c for c, l in countries_labels]):\n        left_coords = pca_result[[i for i, (c, l) in enumerate(countries_labels) if c == country and l == 0]]\n        right_coords = pca_result[[i for i, (c, l) in enumerate(countries_labels) if c == country and l == 1]]\n        if len(left_coords) > 0 and len(right_coords) > 0:\n            plt.plot([left_coords[0][0], right_coords[0][0]], [left_coords[0][1], right_coords[0][1]], 'k-')\n            mid_x = (left_coords[0][0] + right_coords[0][0]) / 2\n            mid_y = (left_coords[0][1] + right_coords[0][1]) / 2\n            plt.text(mid_x, mid_y, country, fontsize=12, color='black', ha='center', va='center')\n\n    plt.xlabel('PCA Component 1')\n    plt.ylabel('PCA Component 2')\n    plt.title('PCA of Mean Representations for Left-Wing and Right-Wing Speeches by Country')\n    plt.grid(True)\n    plt.show()\n\ndef plot_country_sex(pca_result, cs_labels):\n    plt.figure(figsize=(25, 14))\n\n    for i, ((country, sex, label), pca_coord) in enumerate(zip(cs_labels, pca_result)):\n        color = 'red' if label == 0 else 'blue'\n        marker = 'v' if sex == 1 else 'o'\n        plt.scatter(pca_coord[0], pca_coord[1], color=color, marker=marker)\n\n    # Connect the points with lines and add country codes\n    for country in np.unique([c for (c, s, l) in cs_labels]):\n        for sex in np.unique([s for (c, s, l) in cs_labels]):\n            if (country, sex, 0) not in cs_labels or (country, sex, 1) not in cs_labels:\n                continue\n            left_coords = pca_result[[i for i, (c, s, l) in enumerate(cs_labels) if c == country and l == 0 and s == sex]]\n            right_coords = pca_result[[i for i, (c, s, l) in enumerate(cs_labels) if c == country and l == 1 and s == sex]]\n            if len(left_coords) > 0 and len(right_coords) > 0:\n                plt.plot([left_coords[0][0], right_coords[0][0]], [left_coords[0][1], right_coords[0][1]], 'k-')\n                mid_x = (left_coords[0][0] + right_coords[0][0]) / 2\n                mid_y = (left_coords[0][1] + right_coords[0][1]) / 2\n                sex_text = \"Female\" if sex == 0 else \"Male\"\n                text = country + \" - \" + sex_text\n                plt.text(mid_x, mid_y, text, fontsize=12, color='black', ha='center', va='center')\n\n    plt.xlabel('PCA Component 1')\n    plt.ylabel('PCA Component 2')\n    plt.title('PCA of Mean Representations for Left-Wing and Right-Wing Speeches by Country')\n    plt.grid(True)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2025-01-28T10:28:19.985448Z","iopub.execute_input":"2025-01-28T10:28:19.985764Z","iopub.status.idle":"2025-01-28T10:28:20.023040Z","shell.execute_reply.started":"2025-01-28T10:28:19.985741Z","shell.execute_reply":"2025-01-28T10:28:20.022227Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2025-01-28T10:28:29.518795Z","iopub.execute_input":"2025-01-28T10:28:29.519123Z","iopub.status.idle":"2025-01-28T10:28:29.535294Z","shell.execute_reply.started":"2025-01-28T10:28:29.519098Z","shell.execute_reply":"2025-01-28T10:28:29.534488Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib\nfont = {'family' : 'normal',\n        'weight' : 'bold',\n        'size'   : 15}\n\nmatplotlib.rc('font', **font)","metadata":{"execution":{"iopub.status.busy":"2025-01-28T10:28:31.129368Z","iopub.execute_input":"2025-01-28T10:28:31.129659Z","iopub.status.idle":"2025-01-28T10:28:31.133486Z","shell.execute_reply.started":"2025-01-28T10:28:31.129637Z","shell.execute_reply":"2025-01-28T10:28:31.132663Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get BERT representations for the validation data\nval_representations, val_labels, val_countries, val_sexes, val_logits = extract_representations(c_dict['val'])\n#print(val_countries)","metadata":{"execution":{"iopub.status.busy":"2025-01-28T10:28:34.164164Z","iopub.execute_input":"2025-01-28T10:28:34.164519Z","iopub.status.idle":"2025-01-28T10:28:39.129535Z","shell.execute_reply.started":"2025-01-28T10:28:34.164486Z","shell.execute_reply":"2025-01-28T10:28:39.128781Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate mean representations for each country and label\nmean_representations_cval = calculate_mean_by_country(val_countries, val_labels, val_representations, threshold=4)\nprint(\"Calculated all representations!\")\n#print(mean_representations_cval)\n\n# Prepare data for PCA\nmean_reps_cval = np.array(list(mean_representations_cval.values()))\ncountries_labels_cval = list(mean_representations_cval.keys())\n\n# Perform PCA\npca_result_cval = perform_PCA(mean_reps_cval)\n\n#Plot results\nplot_country(pca_result_cval, countries_labels_cval)","metadata":{"execution":{"iopub.status.busy":"2025-01-28T10:37:25.258324Z","iopub.execute_input":"2025-01-28T10:37:25.258659Z","iopub.status.idle":"2025-01-28T10:37:25.876877Z","shell.execute_reply.started":"2025-01-28T10:37:25.258637Z","shell.execute_reply":"2025-01-28T10:37:25.876134Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate mean representations for each country and label\nmean_representations_csval = calculate_mean_by_country_sex(val_countries, val_labels, val_representations, val_sexes, threshold=100)\nprint(\"Calculated all representations!\")\nprint(mean_representations_csval)\n\n# Prepare data for PCA\nmean_reps_csval = np.array(list(mean_representations_csval.values()))\ncountries_labels_csval = list(mean_representations_csval.keys())\n\n# Perform PCA\npca_result_csval = perform_PCA(mean_reps_csval)\n\n#Plot results\nplot_country_sex(pca_result_csval, countries_labels_csval)","metadata":{"execution":{"iopub.status.busy":"2025-01-23T13:56:37.990137Z","iopub.execute_input":"2025-01-23T13:56:37.990498Z","iopub.status.idle":"2025-01-23T13:56:38.384920Z","shell.execute_reply.started":"2025-01-23T13:56:37.990471Z","shell.execute_reply":"2025-01-23T13:56:38.384021Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get BERT representations for the validation data\ntr_representations, tr_labels, tr_countries, tr_sexes, tr_logits = extract_representations(c_dict['train'])","metadata":{"execution":{"iopub.status.busy":"2025-01-28T10:37:42.674043Z","iopub.execute_input":"2025-01-28T10:37:42.674345Z","iopub.status.idle":"2025-01-28T10:38:20.997159Z","shell.execute_reply.started":"2025-01-28T10:37:42.674322Z","shell.execute_reply":"2025-01-28T10:38:20.996345Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate mean representations for each country and label\nmean_representations_ctr = calculate_mean_by_country(tr_countries, tr_labels, tr_representations, threshold=30)\nprint(\"Calculated all representations!\")\n\n# Prepare data for PCA\nmean_reps_ctr = np.array(list(mean_representations_ctr.values()))\ncountries_labels_ctr = list(mean_representations_ctr.keys())\n\n# Perform PCA\npca_result_ctr = perform_PCA(mean_reps_ctr)\n\n#Plot results\nplot_country(pca_result_ctr, countries_labels_ctr)","metadata":{"execution":{"iopub.status.busy":"2025-01-28T10:39:04.267210Z","iopub.execute_input":"2025-01-28T10:39:04.267502Z","iopub.status.idle":"2025-01-28T10:39:04.877473Z","shell.execute_reply.started":"2025-01-28T10:39:04.267480Z","shell.execute_reply":"2025-01-28T10:39:04.876666Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate mean representations for each country and label\nmean_representations_cstr = calculate_mean_by_country_sex(tr_countries, tr_labels, tr_representations, tr_sexes, threshold=500)\nprint(\"Calculated all representations!\")\n\n# Prepare data for PCA\nmean_reps_cstr = np.array(list(mean_representations_cstr.values()))\ncountries_labels_cstr = list(mean_representations_cstr.keys())\n\n# Perform PCA\npca_result_cstr = perform_PCA(mean_reps_cstr)\n\n#Plot results\nplot_country_sex(pca_result_cstr, countries_labels_cstr)","metadata":{"execution":{"iopub.status.busy":"2025-01-23T13:58:07.581012Z","iopub.execute_input":"2025-01-23T13:58:07.581343Z","iopub.status.idle":"2025-01-23T13:58:08.005693Z","shell.execute_reply.started":"2025-01-23T13:58:07.581318Z","shell.execute_reply":"2025-01-23T13:58:08.004847Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get BERT representations for the validation data\nts_representations, ts_labels, ts_countries, ts_sexes, ts_logits = extract_representations(c_dict['test'])","metadata":{"execution":{"iopub.status.busy":"2025-01-28T10:39:53.622631Z","iopub.execute_input":"2025-01-28T10:39:53.622922Z","iopub.status.idle":"2025-01-28T10:39:58.586891Z","shell.execute_reply.started":"2025-01-28T10:39:53.622898Z","shell.execute_reply":"2025-01-28T10:39:58.586208Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate mean representations for each country and label\nmean_representations_cts = calculate_mean_by_country(ts_countries, ts_labels, ts_representations, threshold=100)\nprint(\"Calculated all representations!\")\n\n# Prepare data for PCA\nmean_reps_cts = np.array(list(mean_representations_cts.values()))\ncountries_labels_cts = list(mean_representations_cts.keys())\n\n# Perform PCA\npca_result_cts = perform_PCA(mean_reps_cts)\n\n#Plot results\nplot_country(pca_result_cts, countries_labels_cts)","metadata":{"execution":{"iopub.status.busy":"2025-01-23T13:58:24.459993Z","iopub.execute_input":"2025-01-23T13:58:24.460354Z","iopub.status.idle":"2025-01-23T13:58:24.818251Z","shell.execute_reply.started":"2025-01-23T13:58:24.460320Z","shell.execute_reply":"2025-01-23T13:58:24.817442Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate mean representations for each country and label\nmean_representations_csts = calculate_mean_by_country_sex(ts_countries, ts_labels, ts_representations, ts_sexes, threshold=200)\nprint(\"Calculated all representations!\")\n\n# Prepare data for PCA\nmean_reps_csts = np.array(list(mean_representations_csts.values()))\ncountries_labels_csts = list(mean_representations_csts.keys())\n\n# Perform PCA\npca_result_csts = perform_PCA(mean_reps_csts)\n\n#Plot results\nplot_country_sex(pca_result_csts, countries_labels_csts)","metadata":{"execution":{"iopub.status.busy":"2025-01-23T13:58:32.284010Z","iopub.execute_input":"2025-01-23T13:58:32.284324Z","iopub.status.idle":"2025-01-23T13:58:32.626664Z","shell.execute_reply.started":"2025-01-23T13:58:32.284303Z","shell.execute_reply":"2025-01-23T13:58:32.625700Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(15, 9))\nc_names = list(map(extract_country_code, list(performance.keys())))\nplt.barh(c_names, list(performance.values()))\nplt.xlabel('Weighted F1')\nplt.title('Weighted F1 by Country')","metadata":{"execution":{"iopub.status.busy":"2025-01-23T13:58:38.760636Z","iopub.execute_input":"2025-01-23T13:58:38.761058Z","iopub.status.idle":"2025-01-23T13:58:39.197001Z","shell.execute_reply.started":"2025-01-23T13:58:38.761011Z","shell.execute_reply":"2025-01-23T13:58:39.196108Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def calculate_mean_probabilities(countries, predictions, labels, threshold = 1):\n    country_means = {}\n    for country in np.unique(countries):\n        #print(f\"Processing country: {country}\")\n        country_indices = countries == country\n        country_labels = labels[country_indices]\n        if country_labels.shape[0] < threshold:\n            continue\n        country_predictions = predictions[country_indices]\n        country_predictions = np.exp(country_predictions)\n        country_predictions = country_predictions / np.sum(country_predictions, axis=1)[:, np.newaxis]\n        if country_labels.size > 0:  \n            right_mean = np.mean(country_predictions[country_labels == 1][:, 1])\n            left_mean = np.mean(country_predictions[country_labels == 0][:, 0])\n            country_means[country] = (right_mean, left_mean)\n            #print(f\"Country: {country}, Right Mean: {right_mean}, Left Mean: {left_mean}\")\n        else:\n            print(f\"No data for country: {country}\")\n    return country_means","metadata":{"execution":{"iopub.status.busy":"2025-01-28T10:40:36.485164Z","iopub.execute_input":"2025-01-28T10:40:36.485471Z","iopub.status.idle":"2025-01-28T10:40:36.490972Z","shell.execute_reply.started":"2025-01-28T10:40:36.485447Z","shell.execute_reply":"2025-01-28T10:40:36.490048Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"country_means = calculate_mean_probabilities(ts_countries, ts_logits, ts_labels, threshold=7)\ncountries = list(country_means.keys())\nright_means = [country_means[c][0] for c in countries]\nleft_means = [country_means[c][1] for c in countries]","metadata":{"execution":{"iopub.status.busy":"2025-01-28T10:43:04.531415Z","iopub.execute_input":"2025-01-28T10:43:04.531720Z","iopub.status.idle":"2025-01-28T10:43:04.537797Z","shell.execute_reply.started":"2025-01-28T10:43:04.531699Z","shell.execute_reply":"2025-01-28T10:43:04.537105Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(15, 9))\nplt.barh(countries, right_means, color='blue')\nplt.xlabel('Mean Probability')\nplt.title('Right-Wing Mean Probabilities by Country')","metadata":{"execution":{"iopub.status.busy":"2025-01-28T10:43:06.944377Z","iopub.execute_input":"2025-01-28T10:43:06.944686Z","iopub.status.idle":"2025-01-28T10:43:07.195164Z","shell.execute_reply.started":"2025-01-28T10:43:06.944660Z","shell.execute_reply":"2025-01-28T10:43:07.194455Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(15, 9))\nplt.barh(countries, left_means, color='red')\nplt.xlabel('Mean Probability')\nplt.title('Left-Wing Mean Probabilities by Country')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2025-01-28T10:43:18.563564Z","iopub.execute_input":"2025-01-28T10:43:18.563852Z","iopub.status.idle":"2025-01-28T10:43:18.804249Z","shell.execute_reply.started":"2025-01-28T10:43:18.563830Z","shell.execute_reply":"2025-01-28T10:43:18.803419Z"},"trusted":true},"outputs":[],"execution_count":null}]}